{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "from date_measurement import DateMeasurement as DM \n",
    "from date_tool import dt_search as dt_search\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_disaster = { \n",
    "    'gempa' : r'gempa|tektonik',\n",
    "    'tsunami' : r'tsunami',\n",
    "    'erupsi' : r'vulkanik|erupsi|letusan|awan panas|lava',\n",
    "    'kekeringan' : r'kekeringan',\n",
    "    'banjir' : r'banjir',\n",
    "    'angin_topan' : r'badai|puting beliung|angin topan|tornado|angin kencang',\n",
    "    'longsor' : r'longsor',\n",
    "    'karhutla' : r'kebakaran hutan|kebakaran lahan|titik panas',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_content_date(content_date, pub_date):\n",
    "    if 0 < len(content_date):\n",
    "        l_date = content_date.split('|')\n",
    "        y_pub = pub_date[:4]\n",
    "        for i, val in enumerate(l_date):\n",
    "            if 10 > len(val):\n",
    "                l_date[i] = y_pub + \"-\" + val\n",
    "    else:\n",
    "        l_date = [pub_date]\n",
    "\n",
    "    l_date = list(set(l_date))\n",
    "    return '|'.join(l_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(pub_date_text, content_text):\n",
    "    pub_date = dt_search.find_dates(pub_date_text, mmdd=False)\n",
    "    content_date = dt_search.find_dates(content_text)    \n",
    "    content_date = refine_content_date(content_date, pub_date)\n",
    "\n",
    "    return pub_date, content_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_re_string(text_id):\n",
    "    ret = r''\n",
    "\n",
    "    for k, v in re_disaster.items():\n",
    "        if k in text_id.lower():\n",
    "            ret = v\n",
    "            break\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_context_text(text_id, text):\n",
    "    st_tokens = sent_tokenize(text)\n",
    "    re_string = get_re_string(text_id)\n",
    "    st_tokens = [ s for s in st_tokens if re.search(re_string, s.lower(), re.I) ]\n",
    "    return ' '.join(st_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = 'C:\\\\Users\\\\dharmapu\\\\Documents\\\\personal\\\\ui\\\\KA-AMSD_src\\\\paper-submission\\\\anotated_data\\\\date-time\\\\date-time_text.xlsx'\n",
    "f_ref = 'C:\\\\Users\\\\dharmapu\\\\Documents\\\\personal\\\\ui\\\\KA-AMSD_src\\\\paper-submission\\\\anotated_data\\\\date-time\\\\date-time.xlsx'\n",
    "\n",
    "df = pd.read_excel(f_in)\n",
    "df_ref = pd.read_excel(f_ref)\n",
    "df['date_text'] = df_ref['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text_id = row['id']\n",
    "    pub_date_text = row['date']\n",
    "    content_text = row['title'] + ' ' + row['content']\n",
    "    content_text = filter_context_text(text_id, content_text)\n",
    "\n",
    "    pub_date, content_date = extract_date(pub_date_text, content_text)\n",
    "\n",
    "    df.loc[index, 'pred_date_pub'] = pub_date\n",
    "    df.loc[index, 'pred_date_text'] = content_date\n",
    "\n",
    "    # prepare \n",
    "    if \"nan\".lower() == str(row['date_text']).lower():\n",
    "        ref_date = pub_date\n",
    "    else:  \n",
    "        ref_date = row['date_text']\n",
    "    \n",
    "    df.loc[index, 'ref_date'] = ref_date\n",
    "\n",
    "    pred_date = content_date\n",
    "    l_true = ref_date.split('|')\n",
    "    l_pred = pred_date.split('|')\n",
    "\n",
    "    # clean\n",
    "    l_true = [ e.replace('\\'', '') for e in l_true ]\n",
    "    l_pred = [ e.replace('\\'', '') for e in l_pred ]\n",
    "    \n",
    "    dm = DM(l_true, l_pred)\n",
    "    df.loc[index, 'jc_sim'] = dm.jaccard_simmilarity()\n",
    "    df.loc[index, 'pre'] = dm.precision()\n",
    "    df.loc[index, 'rec'] = dm.recall()\n",
    "    df.loc[index, 'f1'] = dm.f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['MEAN', 'N/A', 'N/A', 'N/A', 'N/A', '0.662537', '0.683484', '0.716944', '0.685879']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id              date_text               ref_date  \\\n",
       "0     angin_topan_0001             2018-09-30             2018-09-30   \n",
       "1     angin_topan_0002             2016-11-04             2016-11-04   \n",
       "2     angin_topan_0003             2018-01-03             2018-01-03   \n",
       "3     angin_topan_0005             2017-09-04             2017-09-04   \n",
       "4     angin_topan_0006  2019-08-19|2019-08-18  2019-08-19|2019-08-18   \n",
       "...                ...                    ...                    ...   \n",
       "2208      tsunami_1154             2018-09-28             2018-09-28   \n",
       "2209      tsunami_1158                    NaN             2018-10-03   \n",
       "2210      tsunami_1160             2018-12-22             2018-12-22   \n",
       "2211      tsunami_1163             2018-09-28             2018-09-28   \n",
       "2212              MEAN                    N/A                    N/A   \n",
       "\n",
       "     pred_date_pub         pred_date_text    jc_sim       pre       rec  \\\n",
       "0       2018-10-01             2018-09-30         1         1         1   \n",
       "1       2016-11-11             2016-11-04         1         1         1   \n",
       "2       2018-01-04             2018-01-04         0         0         0   \n",
       "3       2017-04-10             2017-04-09         0         0         0   \n",
       "4       2019-08-20             2019-08-19       0.5         1       0.5   \n",
       "...            ...                    ...       ...       ...       ...   \n",
       "2208    2018-09-29             2018-09-28         1         1         1   \n",
       "2209    2018-10-03             2018-10-03         1         1         1   \n",
       "2210    2018-12-25  2018-12-22|2018-12-24       0.5       0.5         1   \n",
       "2211    2018-09-29             2018-09-29         0         0         0   \n",
       "2212           N/A                    N/A  0.662537  0.683484  0.716944   \n",
       "\n",
       "            f1  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4     0.666667  \n",
       "...        ...  \n",
       "2208         1  \n",
       "2209         1  \n",
       "2210  0.666667  \n",
       "2211         0  \n",
       "2212  0.685879  \n",
       "\n",
       "[2213 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date_text</th>\n      <th>ref_date</th>\n      <th>pred_date_pub</th>\n      <th>pred_date_text</th>\n      <th>jc_sim</th>\n      <th>pre</th>\n      <th>rec</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>angin_topan_0001</td>\n      <td>2018-09-30</td>\n      <td>2018-09-30</td>\n      <td>2018-10-01</td>\n      <td>2018-09-30</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>angin_topan_0002</td>\n      <td>2016-11-04</td>\n      <td>2016-11-04</td>\n      <td>2016-11-11</td>\n      <td>2016-11-04</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>angin_topan_0003</td>\n      <td>2018-01-03</td>\n      <td>2018-01-03</td>\n      <td>2018-01-04</td>\n      <td>2018-01-04</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>angin_topan_0005</td>\n      <td>2017-09-04</td>\n      <td>2017-09-04</td>\n      <td>2017-04-10</td>\n      <td>2017-04-09</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>angin_topan_0006</td>\n      <td>2019-08-19|2019-08-18</td>\n      <td>2019-08-19|2019-08-18</td>\n      <td>2019-08-20</td>\n      <td>2019-08-19</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2208</th>\n      <td>tsunami_1154</td>\n      <td>2018-09-28</td>\n      <td>2018-09-28</td>\n      <td>2018-09-29</td>\n      <td>2018-09-28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2209</th>\n      <td>tsunami_1158</td>\n      <td>NaN</td>\n      <td>2018-10-03</td>\n      <td>2018-10-03</td>\n      <td>2018-10-03</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2210</th>\n      <td>tsunami_1160</td>\n      <td>2018-12-22</td>\n      <td>2018-12-22</td>\n      <td>2018-12-25</td>\n      <td>2018-12-22|2018-12-24</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>1</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>2211</th>\n      <td>tsunami_1163</td>\n      <td>2018-09-28</td>\n      <td>2018-09-28</td>\n      <td>2018-09-29</td>\n      <td>2018-09-29</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2212</th>\n      <td>MEAN</td>\n      <td>N/A</td>\n      <td>N/A</td>\n      <td>N/A</td>\n      <td>N/A</td>\n      <td>0.662537</td>\n      <td>0.683484</td>\n      <td>0.716944</td>\n      <td>0.685879</td>\n    </tr>\n  </tbody>\n</table>\n<p>2213 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_out = df[['id', 'date_text', 'ref_date', 'pred_date_pub', 'pred_date_text', 'jc_sim', 'pre', 'rec', 'f1']]\n",
    "\n",
    "columns = ['jc_sim', 'pre', 'rec', 'f1'] \n",
    "means_list = [ \"{:.6f}\".format(df_out[c].mean()) for c in columns ]\n",
    "#means_list\n",
    "\n",
    "lst = ['MEAN', 'N/A', 'N/A', 'N/A', 'N/A']\n",
    "lst = lst + means_list\n",
    "print(lst)\n",
    "\n",
    "df_tmp = df_out.copy()\n",
    "df_tmp.loc[len(df_tmp)] = lst\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_out = f_in.replace('.xlsx', '_rslt_spec_st.xlsx')\n",
    "df_tmp.to_excel(f_out, index=False)"
   ]
  }
 ]
}